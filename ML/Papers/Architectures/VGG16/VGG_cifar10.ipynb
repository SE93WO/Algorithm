{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEWO.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "polVoR7ALHu-",
        "colab_type": "code",
        "outputId": "25af56f8-c698-43d3-fc15-3e009607b556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# !kill -9 -1 or !pkill -9 -f ipykernel_launcher"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vtp9xikALsD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e5e0fdc1-b9fb-48da-e417-a588ac55b285"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AvcPeNpFMZES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg = tf.keras.models.Sequential()\n",
        "\n",
        "# Layer 1\n",
        "vgg.add(tf.layers.Conv2D(64, kernel_size=(3, 3), padding='same', input_shape = x_train.shape[1:], activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "# Layer 2\n",
        "vgg.add(tf.layers.Conv2D(128, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Conv2D(128, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "# Layer 3\n",
        "vgg.add(tf.layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.MaxPooling2D(pool_size=(2, 2),  strides=2))\n",
        "\n",
        "# Layer 4\n",
        "vgg.add(tf.layers.Conv2D(512, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Conv2D(512, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "# Layer 5\n",
        "vgg.add(tf.layers.Conv2D(512, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Conv2D(512, kernel_size=(3, 3), padding='same', activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "# Layer 6\n",
        "vgg.add(tf.layers.Flatten())\n",
        "vgg.add(tf.layers.Dense(1024, activation=tf.nn.relu))\n",
        "vgg.add(tf.keras.layers.BatchNormalization())\n",
        "vgg.add(tf.layers.Dropout(0.5))\n",
        "vgg.add(tf.layers.Dense(10, activation=tf.nn.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NCZ_7QDRBfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "vgg.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TyDb3-FiRBuJ",
        "colab_type": "code",
        "outputId": "7ba3beec-a804-4307-fef3-35f66abf664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2892
        }
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "        width_shift_range=0.1, height_shift_range=0.1)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "vgg.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,\n",
        "                    epochs=125,\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "\n",
        "vgg.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 2.2698 - acc: 0.2864 - val_loss: 6.9905 - val_acc: 0.1028\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 1.9944 - acc: 0.3445 - val_loss: 1.7696 - val_acc: 0.3312\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 1.8203 - acc: 0.4072 - val_loss: 1.4880 - val_acc: 0.4490\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 1.4567 - acc: 0.4679 - val_loss: 1.4424 - val_acc: 0.5012\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 1.3385 - acc: 0.5163 - val_loss: 1.2693 - val_acc: 0.5432\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 1.2225 - acc: 0.5613 - val_loss: 1.3544 - val_acc: 0.5416\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 1.1044 - acc: 0.6050 - val_loss: 1.3286 - val_acc: 0.5651\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.9950 - acc: 0.6467 - val_loss: 0.9929 - val_acc: 0.6628\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.9020 - acc: 0.6817 - val_loss: 0.9624 - val_acc: 0.6913\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.8159 - acc: 0.7147 - val_loss: 0.9948 - val_acc: 0.6891\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.7469 - acc: 0.7387 - val_loss: 0.7756 - val_acc: 0.7407\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.6852 - acc: 0.7597 - val_loss: 0.7503 - val_acc: 0.7563\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.6322 - acc: 0.7788 - val_loss: 0.9360 - val_acc: 0.7550\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.5885 - acc: 0.7949 - val_loss: 0.6970 - val_acc: 0.7756\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 68s 88ms/step - loss: 0.5496 - acc: 0.8091 - val_loss: 0.7356 - val_acc: 0.7864\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 68s 86ms/step - loss: 0.5198 - acc: 0.8201 - val_loss: 0.7771 - val_acc: 0.7749\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 68s 88ms/step - loss: 0.4894 - acc: 0.8298 - val_loss: 0.7592 - val_acc: 0.7702\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.4653 - acc: 0.8388 - val_loss: 0.6625 - val_acc: 0.8070\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.4338 - acc: 0.8491 - val_loss: 0.6873 - val_acc: 0.7965\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.4108 - acc: 0.8568 - val_loss: 0.7775 - val_acc: 0.7884\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.3916 - acc: 0.8626 - val_loss: 0.6573 - val_acc: 0.8119\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.3689 - acc: 0.8708 - val_loss: 0.6697 - val_acc: 0.8000\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.3512 - acc: 0.8778 - val_loss: 0.6733 - val_acc: 0.8085\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.3341 - acc: 0.8831 - val_loss: 0.5998 - val_acc: 0.8178\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.3160 - acc: 0.8885 - val_loss: 0.6828 - val_acc: 0.8208\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.2980 - acc: 0.8939 - val_loss: 0.6219 - val_acc: 0.8256\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.2848 - acc: 0.8999 - val_loss: 0.6406 - val_acc: 0.8265\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.2794 - acc: 0.9035 - val_loss: 0.6431 - val_acc: 0.8265\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.2637 - acc: 0.9085 - val_loss: 0.7469 - val_acc: 0.8213\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.2478 - acc: 0.9137 - val_loss: 0.5814 - val_acc: 0.8397\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.2370 - acc: 0.9174 - val_loss: 0.9477 - val_acc: 0.8177\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.2293 - acc: 0.9202 - val_loss: 0.5829 - val_acc: 0.8385\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.2184 - acc: 0.9242 - val_loss: 0.5697 - val_acc: 0.8435\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.2060 - acc: 0.9277 - val_loss: 0.6767 - val_acc: 0.8317\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.1953 - acc: 0.9314 - val_loss: 0.7033 - val_acc: 0.8310\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.1903 - acc: 0.9337 - val_loss: 0.5903 - val_acc: 0.8473\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.1843 - acc: 0.9355 - val_loss: 0.5778 - val_acc: 0.8496\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1754 - acc: 0.9390 - val_loss: 0.6869 - val_acc: 0.8095\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 69s 89ms/step - loss: 0.1725 - acc: 0.9386 - val_loss: 0.6042 - val_acc: 0.8455\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1598 - acc: 0.9438 - val_loss: 0.6259 - val_acc: 0.8430\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1505 - acc: 0.9484 - val_loss: 0.6336 - val_acc: 0.8413\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1499 - acc: 0.9481 - val_loss: 0.5696 - val_acc: 0.8545\n",
            "Epoch 43/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1450 - acc: 0.9489 - val_loss: 0.5769 - val_acc: 0.8458\n",
            "Epoch 44/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1324 - acc: 0.9539 - val_loss: 0.6138 - val_acc: 0.8465\n",
            "Epoch 45/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1327 - acc: 0.9543 - val_loss: 0.5782 - val_acc: 0.8533\n",
            "Epoch 46/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1275 - acc: 0.9554 - val_loss: 0.6049 - val_acc: 0.8480\n",
            "Epoch 47/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1219 - acc: 0.9573 - val_loss: 0.6001 - val_acc: 0.8587\n",
            "Epoch 48/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1165 - acc: 0.9593 - val_loss: 0.6518 - val_acc: 0.8505\n",
            "Epoch 49/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.1135 - acc: 0.9612 - val_loss: 0.6493 - val_acc: 0.8551\n",
            "Epoch 50/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.1045 - acc: 0.9635 - val_loss: 0.7061 - val_acc: 0.8337\n",
            "Epoch 51/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.1069 - acc: 0.9625 - val_loss: 0.6289 - val_acc: 0.8572\n",
            "Epoch 52/125\n",
            "781/781 [==============================] - 67s 86ms/step - loss: 0.1012 - acc: 0.9639 - val_loss: 0.6471 - val_acc: 0.8506\n",
            "Epoch 53/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0979 - acc: 0.9661 - val_loss: 0.6594 - val_acc: 0.8468\n",
            "Epoch 54/125\n",
            "781/781 [==============================] - 66s 84ms/step - loss: 0.0949 - acc: 0.9664 - val_loss: 0.5862 - val_acc: 0.8631\n",
            "Epoch 55/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0944 - acc: 0.9669 - val_loss: 0.6611 - val_acc: 0.8525\n",
            "Epoch 56/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0914 - acc: 0.9673 - val_loss: 0.6172 - val_acc: 0.8548\n",
            "Epoch 57/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0905 - acc: 0.9679 - val_loss: 0.6313 - val_acc: 0.8549\n",
            "Epoch 58/125\n",
            "781/781 [==============================] - 78s 100ms/step - loss: 0.0822 - acc: 0.9712 - val_loss: 0.6237 - val_acc: 0.8614\n",
            "Epoch 59/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0810 - acc: 0.9714 - val_loss: 0.6113 - val_acc: 0.8611\n",
            "Epoch 60/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0773 - acc: 0.9732 - val_loss: 0.6196 - val_acc: 0.8568\n",
            "Epoch 61/125\n",
            "781/781 [==============================] - 80s 103ms/step - loss: 0.0739 - acc: 0.9740 - val_loss: 0.6269 - val_acc: 0.8640\n",
            "Epoch 62/125\n",
            "781/781 [==============================] - 70s 89ms/step - loss: 0.0762 - acc: 0.9740 - val_loss: 0.6098 - val_acc: 0.8664\n",
            "Epoch 63/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0749 - acc: 0.9742 - val_loss: 0.6318 - val_acc: 0.8626\n",
            "Epoch 64/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0697 - acc: 0.9767 - val_loss: 0.6308 - val_acc: 0.8612\n",
            "Epoch 65/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0716 - acc: 0.9752 - val_loss: 0.6040 - val_acc: 0.8632\n",
            "Epoch 66/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0685 - acc: 0.9764 - val_loss: 0.6226 - val_acc: 0.8603\n",
            "Epoch 67/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0648 - acc: 0.9776 - val_loss: 0.6581 - val_acc: 0.8583\n",
            "Epoch 68/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0620 - acc: 0.9783 - val_loss: 0.6094 - val_acc: 0.8632\n",
            "Epoch 69/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0613 - acc: 0.9791 - val_loss: 0.6328 - val_acc: 0.8667\n",
            "Epoch 70/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0612 - acc: 0.9786 - val_loss: 0.6372 - val_acc: 0.8606\n",
            "Epoch 71/125\n",
            "781/781 [==============================] - 70s 89ms/step - loss: 0.0611 - acc: 0.9784 - val_loss: 0.6356 - val_acc: 0.8647\n",
            "Epoch 72/125\n",
            "781/781 [==============================] - 69s 88ms/step - loss: 0.0579 - acc: 0.9804 - val_loss: 0.6176 - val_acc: 0.8691\n",
            "Epoch 73/125\n",
            "781/781 [==============================] - 70s 89ms/step - loss: 0.0563 - acc: 0.9796 - val_loss: 0.7126 - val_acc: 0.8535\n",
            "Epoch 74/125\n",
            "781/781 [==============================] - 68s 87ms/step - loss: 0.0582 - acc: 0.9799 - val_loss: 0.6517 - val_acc: 0.8662\n",
            "Epoch 75/125\n",
            "781/781 [==============================] - 70s 89ms/step - loss: 0.0552 - acc: 0.9806 - val_loss: 0.6497 - val_acc: 0.8651\n",
            "Epoch 76/125\n",
            "781/781 [==============================] - 70s 89ms/step - loss: 0.0540 - acc: 0.9813 - val_loss: 0.6284 - val_acc: 0.8660\n",
            "Epoch 77/125\n",
            "242/781 [========>.....................] - ETA: 46s - loss: 0.0554 - acc: 0.9811Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PaZWwDwabyRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}